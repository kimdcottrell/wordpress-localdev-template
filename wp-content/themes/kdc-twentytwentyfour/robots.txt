# suggest to many AI models to not use your site as training data, but still give the okay for bing, google, and searchgpt to crawl.
# this file will need to show up on production as https://yoursite.com/robots.txt 
# you may need to move this file to make that happen.
# there's a rule in the nginx config that makes it show up correctly in local development.
# source: https://www.coywolf.news/seo/how-to-be-in-chatgpt-search-results-without-training-their-ai-models/
#
# robots.txt is only a suggestion. to truly ban these, you will need to adjust rules in your load balancer/web server/etc.
User-agent: Amazonbot
User-agent: Anthropic-ai
User-agent: Applebot-Extended
User-agent: AwarioRssBot
User-agent: AwarioSmartBot
User-agent: Bytespider
User-agent: CCBot
User-agent: ChatGPT-User
User-agent: ClaudeBot
User-agent: Claude-Web
User-agent: Cohere-ai
User-agent: DataForSeoBot
User-agent: FacebookBot
User-agent: Google-Extended
User-agent: GPTBot
User-agent: ImagesiftBot
User-agent: Magpie-crawler
User-agent: Omgili
User-agent: Omgilibot
User-agent: Peer39_crawler
User-agent: Peer39_crawler/1.0
User-agent: PerplexityBot
User-agent: YouBot
Disallow: /